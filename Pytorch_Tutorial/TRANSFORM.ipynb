{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEm3OzPpa4QDgS9sQq2QvM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 변형 (TRANSFORMS)\n","데이터가 항상 머신러닝 알고리즘 학습에 필요한 최종 처리가 된 형태로 제공되지는 않습니다. **변형**을 해서 데이터를 조작하고 학습에 적합하게 만듭니다.\n","\n","모든 TorchVision 데이터셋들은 변형 로직을 갖는, 호출 가능한 객체(callable)를 받는 매개변수 두개 특징(feature)을 변경하기 위한 transform과 정답을 변형하기 위한 target_transform 을 갖습니다.\n","\n","FashionMNIST 특징은 PIL Image 형식이며, 정답은 정수 입니다. 학습을 하려면 정규화된 텐서 형태의 특징과 one-hot으로 encode된 텐서 형태의 정답이 필요 합니다. 이러한 변형을 하기 위해 ToTensor와 Lambda를 사용합니다."],"metadata":{"id":"CwVowjrcN-mM"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzgqHoS9Nrph","executionInfo":{"status":"ok","timestamp":1691046809183,"user_tz":-540,"elapsed":5201,"user":{"displayName":"안창준","userId":"13592319070657983406"}},"outputId":"f5b3ad64-65e3-4ae7-b6e4-2a39ab55d036"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 18233366.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 333383.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 6043992.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 5552141.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","ds = datasets.FashionMNIST(\n","    root = \"./data\",\n","    train = True,\n","    download = True,\n","    transform = ToTensor(),\n","    target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value = 1))\n",")"]},{"cell_type":"markdown","source":["# ToTensor()\n","ToTensor는 PIL Image나 Numpy ndarray를 FloatTensor()로 변환하고, 이미지의 픽셀의 크기 값을 [0, 1] 범위로 비례하여 조정합니다.\n","\n","# Lambda 변형(Transform)\n","Lambda 변형은 사용자 정의 람다 함수를 적용합니다. 여기에서는 정수를 one-hot 으로 encode된 텐서로 바꾸는 함수를 정의합니다.\n","이 함수는 먼저 크기 10짜리 zero tensor를 만들고, scatter_ 를 호출하여 주어진 정답 y에 해당하는 인덱스에 value = 1을 할당합니다."],"metadata":{"id":"AvXyOX5EPssF"}},{"cell_type":"code","source":[],"metadata":{"id":"3tuXtssiPmBb"},"execution_count":null,"outputs":[]}]}